{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import shap\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "base_data_path = r\"dataset\\data_preprocessed\\log_spectrograms\"\n",
    "train_data_path = base_data_path + r\"\\train\"\n",
    "valid_data_path = base_data_path + r\"\\valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_stats(train_data_path, stats_file):\n",
    "    print(\"Calculating dataset statistics for normalization...\")\n",
    "    all_pixels = []\n",
    "    for root, dirs, files in os.walk(train_data_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                img_path = os.path.join(root, file)\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "                all_pixels.append(np.array(image) / 255.0)\n",
    "    all_pixels = np.concatenate([img.reshape(-1, 3) for img in all_pixels], axis=0)\n",
    "    mean = all_pixels.mean(axis=0)\n",
    "    std = all_pixels.std(axis=0)\n",
    "    \n",
    "    # Save statistics to a file\n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump({\"mean\": mean.tolist(), \"std\": std.tolist()}, f)\n",
    "    \n",
    "    print(f\"Mean: {mean}, Std: {std} (calculated and saved)\")\n",
    "    return mean, std\n",
    "\n",
    "def load_stats(stats_file):\n",
    "    with open(stats_file, \"r\") as f:\n",
    "        stats = json.load(f)\n",
    "    mean = np.array(stats[\"mean\"])\n",
    "    std = np.array(stats[\"std\"])\n",
    "    print(f\"Mean: {mean}, Std: {std} (loaded from file)\")\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_file = base_data_path + r\"\\metrics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataset statistics for normalization...\n",
      "Mean: [0.2180967  0.22171669 0.20659676], Std: [0.2255099  0.22619834 0.22069111] (calculated and saved)\n",
      "Mean:  [0.2180967  0.22171669 0.20659676] Std:  [0.2255099  0.22619834 0.22069111]\n"
     ]
    }
   ],
   "source": [
    "# Load\\Calculate mean and std dynamically \n",
    "\n",
    "if os.path.exists(stats_file):\n",
    "    # Load saved statistics\n",
    "    mean, std = load_stats(stats_file)\n",
    "else:\n",
    "    # Calculate and save statistics\n",
    "    # Approximately 3 minutes for the entire training set (~50'000 images)\n",
    "    mean, std = calculate_and_save_stats(train_data_path, stats_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset\n",
    "class EarthquakeDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.file_list = [f for f in os.listdir(data_path) if f.endswith(\".png\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.file_list[idx]\n",
    "        img_path = os.path.join(self.data_path, img_name)\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Extract label from filename\n",
    "        if \"_post.png\" in img_name:\n",
    "            label = 1  # Aftershock\n",
    "        elif \"_pre.png\" in img_name:\n",
    "            label = 0  # Mainshock\n",
    "        else:\n",
    "            raise ValueError(\"Filename does not match expected pattern\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "dataset = EarthquakeDataset(train_data_path, transform=transform)\n",
    "valid_dataset = EarthquakeDataset(valid_data_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.BatchNorm3 = nn.BatchNorm2d(128)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Update fc1 to reflect the correct input size after convolution and pooling\n",
    "        self.fc1 = nn.Linear(128 * 4 * 19, 128)  # Adjusted based on H=33, W=153\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.maxpool(self.BatchNorm1(self.conv1(x))))\n",
    "        x = self.relu(self.maxpool(self.BatchNorm2(self.conv2(x))))\n",
    "        x = self.relu(self.BatchNorm3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = CNN2D(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, dataloader, valid_dataloader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        total_batches = len(dataloader)  # Total number of batches in the training set\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate the percentage of the training set trained on\n",
    "            percent_trained = (batch_idx + 1) / total_batches * 100\n",
    "\n",
    "            # Print progress on the same line\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{total_batches} - {percent_trained:.2f}% of training set trained\", end='\\r')\n",
    "            sys.stdout.flush()  # Force the output to be updated immediately\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        train_accuracy = calculate_accuracy(model, dataloader)\n",
    "        valid_accuracy = calculate_accuracy(model, valid_dataloader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 85/1739 - 4.89% of training set trained\r"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, dataloader, valid_dataloader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), r\"trained_models\\first_attempt_cnn2d.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "loaded_model = CNN2D(num_classes=2).to(device)\n",
    "loaded_model.load_state_dict(torch.load(\"trained_models\\first_attempt_cnn2d.pth\", map_location=device))\n",
    "loaded_model.eval()\n",
    "print(\"Model successfully loaded and ready for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP explainability\n",
    "model.eval()\n",
    "images, _ = next(iter(dataloader))\n",
    "images = images.to(device)\n",
    "\n",
    "# Define a SHAP explainer\n",
    "def predict(images):\n",
    "    with torch.no_grad():\n",
    "        logits = model(images)\n",
    "        probs = nn.Softmax(dim=1)(logits)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "explainer = shap.DeepExplainer(model, images)\n",
    "shap_values = explainer.shap_values(images)\n",
    "\n",
    "# Visualize SHAP explanations\n",
    "shap.image_plot(shap_values, images.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN_EQML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
