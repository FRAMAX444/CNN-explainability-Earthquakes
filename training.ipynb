{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miche\\OneDrive\\Desktop\\EQML Project\\CNN-explainability-Earthquakes\\CNN_EQML\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import shap\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "data_path = \"E:\\\\EQML_Project\\\\data_preprocessed\\\\log_spectrograms\\\\train\"\n",
    "\n",
    "# Define custom dataset\n",
    "class EarthquakeDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.file_list = [f for f in os.listdir(data_path) if f.endswith(\".png\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.file_list[idx]\n",
    "        img_path = os.path.join(self.data_path, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Extract label from filename\n",
    "        if \"_post.png\" in img_name:\n",
    "            label = 1  # Aftershock\n",
    "        elif \"_pre.png\" in img_name:\n",
    "            label = 0  # Mainshock\n",
    "        else:\n",
    "            raise ValueError(\"Filename does not match expected pattern\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = EarthquakeDataset(data_path, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.BatchNorm3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.BatchNorm4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.BatchNorm5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.BatchNorm6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.BatchNorm7 = nn.BatchNorm2d(256)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(256 * 4 * 2, num_classes)  # Adjust based on input size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.maxpool(self.BatchNorm1(self.conv1(x))))\n",
    "        x = self.relu(self.maxpool(self.BatchNorm2(self.conv2(x))))\n",
    "        x = self.relu(self.maxpool(self.BatchNorm3(self.conv3(x))))\n",
    "        x = self.relu(self.maxpool(self.BatchNorm4(self.conv4(x))))\n",
    "        x = self.relu(self.maxpool(self.BatchNorm5(self.conv5(x))))\n",
    "        x = self.relu(self.maxpool(self.BatchNorm6(self.conv6(x))))\n",
    "        x = self.relu(self.maxpool(self.BatchNorm7(self.conv7(x))))\n",
    "        x = self.dropout(self.flatten(x))\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN2D(num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader, desc = \"dataloaders\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP explainability\n",
    "model.eval()\n",
    "\n",
    "# Select a batch of images to explain\n",
    "images, _ = next(iter(dataloader))\n",
    "images = images.to(device)\n",
    "\n",
    "# Define a SHAP explainer\n",
    "def predict(images):\n",
    "    with torch.no_grad():\n",
    "        logits = model(images)\n",
    "        probs = nn.Softmax(dim=1)(logits)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "explainer = shap.DeepExplainer(model, images)\n",
    "shap_values = explainer.shap_values(images)\n",
    "\n",
    "# Visualize SHAP explanations\n",
    "shap.image_plot(shap_values, images.cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN_EQML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
